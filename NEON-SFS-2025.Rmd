---
syncID: # What is this?
title: "Linking NEON aquatic observational and instrument data to answer critical questions in aquatic ecology at the continental scale"
description: "" # Add description
dateCreated: 2025-04-28
authors: Zachary Nickerson, Stephanie Parker, Bobby Hensley, Nick Harrison
estimatedTime: 2 hours
packagesLibraries: neonUtilities, ggplot2, lubridate, plyr
topics: data-management, rep-sci
languageTool: R, API
code1: R/download-ais-data/download-NEON-AIS-data.R
tutorialSeries:
urlTitle: explore-neon-ais-data
editor_options: 
  chunk_output_type: inline
---

## Introduction Links

Getting started with NEON data: https://www.neonscience.org/resources/getting-started-neon-data-resources

Contact us form: https://www.neonscience.org/about/contact-us

Teaching Modules: https://www.neonscience.org/resources/learning-hub/teaching-modules <br />
QUBES modules: https://qubeshub.org/community/groups/neon/educational_resources <br />
EDDIE modules : https://serc.carleton.edu/eddie/macrosystems/index.html

Spatial data and maps: https://neon.maps.arcgis.com/home/index.html

NEON data portal: https://data.neonscience.org/

NEONScience GitHub repo: https://github.com/NEONScience <br />
SFS 2025 NEON Workshop GitHub repo:
<https://github.com/NEONScience/WORKSHOP-SFS-2025>

## Tutorial

This tutorial covers downloading NEON Aquatic Instrument System (AIS) and 
Aquatic Observation System (AOS) data using the neonUtilities R package, as 
well as basic instruction in beginning to explore and work with the downloaded
data. This includes navigating data documentation, combining data within and 
between data products, visualizing data, and conducting qualitative and 
quantitative analysis with integrated AIS and AOS data. 

<div id="ds-objectives" markdown="1"

## Objectives

After completing this activity, you will be able to:

* Download NEON AIS and AOS data using the `neonUtilities` package.
* Understand downloaded data sets and load them into R for analyses.
* Understand the similarities and linkages between different NEON data products.
* Join data sets within and between data products by standardized variables.
* Plot instrumented and observational data in the same plotting field.

## Things You'll Need To Complete This Tutorial

To complete this tutorial you will need R (version >3.4) and, 
preferably, RStudio loaded on your computer.

### Install R Packages

* **neonUtilities**: Basic functions for accessing NEON data

These packages are on CRAN and can be installed by 
`install.packages()`.

### Additional Resources

* <a href="https://github.com/NEONScience/NEON-Utilities/neonUtilities" target="_blank">GitHub repository for neonUtilities</a>

</div>

## Download Files and Load Directly to R: loadByProduct()

The most popular function in `neonUtilities` is `loadByProduct()`. 
This function downloads data from the NEON API, merges the site-by-month 
files, and loads the resulting data tables into the R environment, 
assigning each data type to the appropriate R class. This is a popular 
choice because it ensures you're always working with the most up-to-date data, 
and it ends with ready-to-use tables in R. However, if you use it in
a workflow you run repeatedly, keep in mind it will re-download the 
data every time.

Before we get the NEON data, we need to install (if not already done) and load 
the neonUtilities R package, as well as other packages we will use in the 
analysis. 

```{r set-up-env, eval=F}
# # Install neonUtilities package if you have not yet.
# install.packages("neonUtilities")
# install.packages("neonOS")
# install.packages("tidyverse")
```

```{r load-packages}
# Set global option to NOT convert all character variables to factors
options(stringsAsFactors=F)

# Load required packages
library(neonUtilities)
library(neonOS)
library(tidyverse)
```

The inputs to `loadByProduct()` control which data to download and how 
to manage the processing. The following are frequently used inputs: 

* `dpID`: the data product ID, e.g. DP1.20288.001
* `site`: defaults to "all", meaning all sites with available data; 
can be a vector of 4-letter NEON site codes, e.g. 
`c("MART","ARIK","BARC")`.
* `startdate` and `enddate`: defaults to NA, meaning all dates 
with available data; or a date in the form YYYY-MM, e.g. 
2017-06. Since NEON data are provided in month packages, finer 
scale querying is not available. Both start and end date are 
inclusive.
* `package`: either basic or expanded data package. Expanded data 
packages generally include additional information about data 
quality, such as individual quality flag test results. Not every 
NEON data product has an expanded package; if the expanded package 
is requested but there isn't one, the basic package will be 
downloaded.
* `release`: The data release to be downloaded; either 'current' 
or the name of a release, e.g. 'RELEASE-2021'. 'current' returns 
provisional data in addition to the most recent release. To 
download only provisional data, use release='PROVISIONAL'. 
Defaults to 'current'. See 
https://www.neonscience.org/data-samples/data-management/data-revisions-releases 
for more information.
* `include.provisional`: Should provisional data be included in the downloaded
files? Defaults to F.
* `timeIndex`: defaults to "all", to download all data; or the 
number of minutes in the averaging interval. See example below; 
only applicable to IS data.
* `check.size`: T or F; should the function pause before downloading 
data and warn you about the size of your download? Defaults to T; if 
you are using this function within a script or batch process you 
will want to set this to F.
* `token`: this allows you to input your NEON API token to obtain faster 
downloads. 
Learn more about NEON API tokens in the <a href="https//:www.neonscience.org/neon-api-tokens-tutorial" target="_blank">**Using an API Token when Accessing NEON Data with neonUtilities** tutorial</a>. 

There are additional inputs you can learn about in the 
<a href="https//:www.neonscience.org/neonDataStackR" target="_blank">**Use the neonUtilities R Package to Access NEON Data** tutorial</a>. 

The `dpID` is the data product identifier of the data you want to 
download. The DPID can be found on the 
<a href="http://data.neonscience.org/data-products/explore" target="_blank">
Explore Data Products page</a>.

It will be in the form DP#.#####.###. For this tutorial, we'll use some data
products collected in NEON's Aquatic Instrument System: 

* DP1.20288.001: Water quality
* DP1.20033.001: Nitrate in surface water
* DP4.00130.001: Continuous discharge

Now it's time to consider the NEON field site of interest. If not specified, 
the default will download a data product from all sites. The following are 
4-letter site codes for NEON's 34 aquatics sites as of 2022:

ARIK = Arikaree River CO        
BARC = Barco Lake FL          
BIGC = Upper Big Creek CA       
BLDE = Black Deer Creek WY      
BLUE = Blue River OK            
BLWA = Black Warrior River AL 
CARI = Caribou Creek AK         
COMO = Como Creek CO          
CRAM = Crampton Lake WI         
CUPE = Rio Cupeyes PR           
FLNT = Flint River GA           
GUIL = Rio Yahuecas PR 
HOPB = Lower Hop Brook MA       
KING = Kings Creek KS         
LECO = LeConte Creek TN         
LEWI = Lewis Run VA             
LIRO = Little Rock Lake WI      
MART = Martha Creek WA
MAYF = Mayfield Creek AL        
MCDI = McDiffett Creek KS    
MCRA = McRae Creek OR           
OKSR = Oksrukuyik Creek AK      
POSE = Posey Creek VA           
PRIN = Pringle Creek TX       
PRLA = Prairie Lake ND          
PRPO = Prairie Pothole ND     
REDB = Red Butte Creek UT       
SUGG = Suggs Lake FL            
SYCA = Sycamore Creek AZ        
TECR = Teakettle Creek CA        
TOMB = Lower Tombigbee River AL  
TOOK = Toolik Lake AK         
WALK = Walker Branch TN         
WLOU = West St Louis Creek CO       

In this exercise, we will pull data from NEON Atlantic Neotropical Domain (D04).
The aquatic sites in D04 are Rio Cupeyes (CUPE) and Rio Yahuecas (GUIL). Just 
substitute the 4-letter site code for any other site at the end of the url. 

* [Learn more about the Rio Cupeyes site (D04-CUPE)](https://www.neonscience.org/field-sites/cupe)
* [Learn more about the Rio Yahuecas site (D04-GUIL)](https://www.neonscience.org/field-sites/guil)

Now let us download our data. We will focus our excercise on 2022-2023 data.
If you are not using a NEON token to download your data, neonUtilities will 
ignore the `token` input. We set `check.size = F` so that the script runs well 
but remember you always want to check your download size first. For this 
exercise, we will focus on the following data products:

**AIS Data Products:**

* Continuous discharge ([DP4.00130.001](https://data.neonscience.org/data-products/DP4.00130.001))
* Temperature (PRT) in surface water ([DP1.20053.001](https://data.neonscience.org/data-products/DP1.20053.001))
* Water quality ([DP1.20288.001](https://data.neonscience.org/data-products/DP1.20288.001))

**AOS Data Products:**

* Macroinvertebrate collection ([DP1.20120.001](https://data.neonscience.org/data-products/DP1.20120.001))

```{r download-data-waq, results='hide'}
# download data of interest - AOS - Macroinvertebrate collection
inv <- neonUtilities::loadByProduct(dpID="DP1.20120.001",
                                    site=c("CUPE","GUIL"), 
                                    startdate="2022-01",
                                    enddate="2023-12",
                                    package="basic",
                                    release= "current",
                                    include.provisional = T,
                                    token = Sys.getenv("NEON_TOKEN"),
                                    check.size = F)

```

## Files Associated with Downloads

The data we've downloaded comes as an object that is a named list of objects. 
To work with each of them, select them from the list using the `$` operator. 

```{r names-waq}
# view all components of the list
names(inv)

```

We can see that there are 10 objects in the downloaded macroinvertebrate 
collection data.

* Three dataframes of data:
  * `inv_fieldData`
  * `inv_persample`
  * `inv_taxonomyProcessed`
* Five metadata files:
  * `categoricalCodes_20120`
  * `issueLog_20120`
  * `readme_20120`
  * `validation_20120`
  * `variables_20120`
* Two data citations:
  * `citation_20120_PROVISIONAL`
  * `citation_20120_RELEASE-2025`

If you'd like you can use the `$` operator to assign an object from an item in 
the list. If you prefer to extract each table from the list and work with it as 
independent objects, which we will do, you can use the `list2env()` function. 

```{r unlist-vars}
# unlist the variables and add to the global environment
list2env(inv,envir = .GlobalEnv)
```

### Explore: Data Citations

Citing sources correctly helps the NEON user community maintain transparency, 
openness, and trust, while also providing a benefit of being able to track the 
impact of NEON on scientific research. Thus, each download of NEON data comes
with proper citations custom to to the download that align with NEON's 
[data citation guidelines](https://www.neonscience.org/data-samples/guidelines-policies/citing)

```{r view-citation}
# view formatted citations for DP1.20120.001 download
cat(citation_20120_PROVISIONAL)
cat("\n\n")
cat(`citation_20120_RELEASE-2025`)
```

### Explore: Metadata

* **categoricalCodes_xxxxx**: Some variables in the data tables are published as
strings and constrained to a standardized list of values (LOV). This file shows
all the LOV options for variables published in this data product.
* **issueLog_xxxxx**: Issues that may impact data quality, or changes to a data
product that affects all sites, are reported in this file.
* **readme_xxxxx**: The readme file provides important information relevant to 
the data product and the specific instance of downloading the data.
* **validation_xxxxx**: If any fields require validation prior to publication, 
those validation rules are reported in this table
* **variables_xxxxx**: This file contains all the variables found in the 
associated data table(s). This includes full definitions, units, and other 
important information. 

```{r view-vars}
# view macroinvertebrate field data
View(variables_20120)
```

### Explore: Dataframes

There will always be one or more dataframes that include the primary data of the
data product you downloaded. Multiple dataframes are available when there are 
related datatables for a single data product.

```{r view-df}
# view macroinvertebrate field data
View(inv_fieldData)
```

<div id="ds-challenge" markdown="1">

### Challenge: Download AIS Data Products
  
Using what you've learned above, can you modify the code to download data for 
the following data products?

* DP4.00130.001: Continuous discharge
* DP1.20053.001: Temperature (PRT) in surface water
* DP1.20288.001: Water quality

</div>

```{r download-data-nsw, results='hide'}
# download data of interest - AIS - Continuous discharge
csd <- neonUtilities::loadByProduct(dpID="DP4.00130.001",
                                    site=c("CUPE","GUIL"), 
                                    startdate="2022-01",
                                    enddate="2023-12",
                                    package="basic",
                                    release= "current",
                                    include.provisional = T,
                                    token = Sys.getenv("NEON_TOKEN"),
                                    check.size = F)

# download data of interest - AIS - Temperature (PRT) in surface water
tsw <- neonUtilities::loadByProduct(dpID="DP1.20053.001",
                                    site=c("CUPE","GUIL"), 
                                    startdate="2022-01",
                                    enddate="2023-12",
                                    package="basic",
                                    release= "current",
                                    include.provisional = T,
                                    token = Sys.getenv("NEON_TOKEN"),
                                    check.size = F)

# download data of interest - AIS - Water quality
waq <- neonUtilities::loadByProduct(dpID="DP1.20288.001",
                                    site=c("CUPE","GUIL"), 
                                    startdate="2022-01",
                                    enddate="2023-12",
                                    package="basic",
                                    release= "current",
                                    include.provisional = T,
                                    token = Sys.getenv("NEON_TOKEN"),
                                    check.size = F)

```

Let's unpack the AIS data products too:

```{r unlist-remainder}
list2env(csd, .GlobalEnv)
list2env(prt, .GlobalEnv)
list2env(wtq, .GlobalEnv)
```

Note that a few more objects were added to the Global Environment, including:

* `csd_continuousDischarge`
  * Continuous discharge (streamflow) data at a 1 minute interval. Being a Level
  4 data product, this data has been cleaned and gap-filled.
* `TSW_30min`
  * Temperature of surface water data at a 30 minute interval
* `waq_instantaneous`
  * Water quality data at a 1 minute interval. This table contains information 
  on specific conductance, dissolved oxygen, pH, turbidity, fluorescent 
  dissolved organic matter (fDOM) and chlorophyll-a.

## Working with AOS Data

The `neonOS` R package was developed to aid in working with NEON Observational
Subsystem (OS) data products. Two functions used in this exercise are:

* `removeDups()`
* `joinTableNEON()`

### Removing Duplicates from OS Data

Duplicates can arise in data, but the `neonOS::removeDups()` function identifies
duplicates in a data table based on primary key information reported in the 
`variables_xxxxx` files included in each data download.

Let's check for duplicates in macroinvertebrate collection data

```{r id-dups}
# what are the primary keys in inv_fieldData?
message("Primary keys in inv_fieldData are: ",
        paste(variables_20120$fieldName[
          variables_20120$table=="inv_fieldData"
          &variables_20120$primaryKey=="Y"
        ],
        collapse = ", ")
        )
# identify duplicates in inv_fieldData
inv_fieldData_dups <- neonOS::removeDups(inv_fieldData,
                                         variables_20120)

# what are the primary keys in inv_persample?
message("Primary keys in inv_persample are: ",
        paste(variables_20120$fieldName[
          variables_20120$table=="inv_persample"
          &variables_20120$primaryKey=="Y"
        ],
        collapse = ", ")
        )
# identify duplicates in inv_persample
inv_persample_dups <- neonOS::removeDups(inv_persample,
                                         variables_20120)

# what are the primary keys in inv_taxonomyProcessed?
message("Primary keys in inv_taxonomyProcessed are: ",
        paste(variables_20120$fieldName[
          variables_20120$table=="inv_taxonomyProcessed"
          &variables_20120$primaryKey=="Y"
        ],
        collapse = ", ")
        )
# identify duplicates in inv_taxonomyProcessed
inv_taxonomyProcessed_dups <- neonOS::removeDups(inv_taxonomyProcessed,
                                         variables_20120)

```

Thankfully, there are no duplicates in any of the AOS tables used in this 
exercise!

### Joining OS Data Tables

Every NEON data product comes with a Quick Start Guide (QSG). The QSGs contain 
basic information to help users familiarize themselves with the data products, 
including description of the data contents, data quality information, common 
calculations or transformations, and, where relevant, algorithm description 
and/or table joining instructions.

The QSG for Macroinvertebrate collection can be found on the data product
landing page: https://data.neonscience.org/data-products/DP1.20120.001

The `neonOS::joinTableNEON()` function uses the table joining information in the
QSG to quickly join two related NEON data tables from the same data product

```{r table-join}
# join inv_fieldData and inv_taxonomyProcessed
inv_fieldTaxJoined <- neonOS::joinTableNEON(inv_fieldData,inv_taxonomyProcessed)

```

Now, with field and taxonomy data joined. Individual taxon identifications are
easily linked to field data such as collection latitude/longitude, habitat type,
sampler type, and substratum class.

## Working with AIS Data

### Data from Different Sensor Locations (HOR)

NEON often collects the same type of data from sensors in different locations. 
These data are delivered together but you will frequently want to plot the data 
separately or only include data from one sensor in your analysis. NEON uses the 
`horizontalPosition` variable in the data tables to describe which sensor 
data is collected from. The `horizontalPosition` is always a three digit number 
for AIS data. Non-shoreline HOR examples as of 2020 at AIS sites include:

The Continuous discharge data product is derived from a single 
`horizontalPosition`, which corresponds to the sensor co-located with the staff 
gauge at the site. This is also the location at which all empirical discharge
measurements are taken.

Let's see from which `horizontalPosition` the Continuous discharge data is
published, and see if the other AIS data products we downloaded have data at
that same position.

```{r csd-hor}
# use dplyr from the tidyverse collection to get all unique horizontal positions
csd_hor <- csd_continuousDischarge%>%
  dplyr::distinct(siteID,stationHorizontalID)
print(csd_hor)

# GUIL has two horizontal positions because the location of the staff gauge
# changed sometime during this time period. At what date did that occur?
max(csd_continuousDischarge$endDate[
  csd_continuousDischarge$siteID=="GUIL"
  &csd_continuousDischarge$stationHorizontalID=="110"
])

```

At CUPE, the continuous discharge data are published from the 110 position, which
is defined as 'water level sensors mounted to a staff gauge at stream sites'.

At GUIL, until 2022-12-12, the continuous discharge data were published from the
110 position. On 2022-12-12, the position changed to 132, which is defined as 
'stand-alone water level sensors at downstream (S2) locations at stream sites.'

Next, let's see which `horizontalPositions` are published in water temperature
and water quality data.

```{r tsw-waq-hor}
# unique horizontal positions in temperature of surface water data
tsw_hor <- TSW_30min%>%
  dplyr::distinct(siteID,horizontalPosition)
print(tsw_hor)

# unique horizontal positions in temperature of surface water data
waq_hor <- waq_instantaneous%>%
  dplyr::distinct(siteID,horizontalPosition)
print(waq_hor)

```

At each site and data product, data are published at the 101 and 102 positions.

* 101 = Sensors on monopod mounts at upstream (S1) locations at stream sites.
* 102 = Sensors on monopod mounts at downstream (S2) locations at stream sites.

For this exercise, we will work with position 102, as the 102 and 132 positions
are co-located at stream sites (the '2' indicates they are both downstream 
instrumentation). The 110 discharge location is not consistently co-located with
upstream (S1) nor downstream (S2) instrumentation.

```{r tsw-waq-hor-subset}
# subset both temperature of surface water and water quality to position 102
subsetHOR <- "102"
TSW_30min <- TSW_30min[
  TSW_30min$horizontalPosition==subsetHOR,
]
waq_instantaneous <- waq_instantaneous[
  waq_instantaneous$horizontalPosition==subsetHOR,
]
```

<div id="ds-challenge" markdown="1">
### Challenge: Average continuous discharge and water quality to 30-min interval

To make the continuous discharge and water quality data easier to work with for 
this exercise, let's use different packages from the `tidyverse` collection to
create 30-min averaged tables.

</div>

```{r 30-min-summ}
# 30-min average of continuous discharge data
CSD_30min <- csd_continuousDischarge%>%
  dplyr::mutate(roundDate=lubridate::round_date(endDate,"30 min"))%>%
  dplyr::group_by(siteID,roundDate)%>%
  dplyr::summarise(dischargeMean=mean(continuousDischarge,na.rm=T),
                   dischargeCountQF=sum(dischargeFinalQFSciRvw,na.rm = T))

# 30-min average of turbidity data
WAQ_30min <- waq_instantaneous%>%
  dplyr::mutate(roundDate=lubridate::round_date(endDateTime,"30 min"))%>%
  dplyr::group_by(siteID,roundDate)%>%
  dplyr::summarise(turbidityMean=mean(turbidity,na.rm=T),
                   turbidityCountQF=sum(turbidityFinalQF,na.rm = T))

```

Notice that we included a summation of the quality flag (QF; binary: 1 = flag, 
0 = no flag) fields in the new tables.

## Plot Data

Now that we have managed the data a bit to make it cleaner and easier to work
with, let's make some initial plots to see the AOS and AIS data separately 
before we begin to investigate questions that involve integrating the data.

### AOS Macroinvertebrate richness and diversity

```{r aos-plot}
names(inv_fieldTaxJoined)

inv_clean <- inv_fieldTaxJoined%>%
  dplyr::filter(is.na(samplingImpractical)
                &!grepl("GRAB|BRYOZOAN",sampleID))

inv_clean$abun_M2 <- inv_clean$estimatedTotalCount/inv_clean$benthicArea
inv_clean <- inv_clean[order(inv_clean$abun_M2, inv_clean$scientificName),]

inv_clean_summ <- inv_clean%>%
  dplyr::group_by(siteID,eventID,sampleID,habitatType,samplerType,boutNumber)%>%
  dplyr::summarize(abun_M2_sum = sum(abun_M2, na.rm = TRUE))

inv_clean_sum2 <- inv_clean_summ%>% 
  dplyr::group_by(siteID,eventID,habitatType,samplerType,boutNumber)%>%
  dplyr::summarise_each(funs(mean,sd,se=sd(.)/sqrt(n())))%>%
  dplyr::mutate(year=substr(eventID, 6,9),
                yearBout=paste(year,"Bout",boutNumber, sep = "."))

inv_abundance <- inv_clean_sum2%>%
  ggplot2::ggplot(aes(fill=samplerType, y=abun_M2_sum_mean, x=yearBout))+
  ggplot2::geom_bar(position="dodge", stat="identity")+
  ggplot2::geom_errorbar(aes(x=yearBout, 
                             ymin=abun_M2_sum_mean-abun_M2_sum_se, 
                             ymax=abun_M2_sum_mean+abun_M2_sum_se),
                         width=0.4,colour="black",alpha=3.0,linewidth=0.2,
                         position=position_dodge(0.8))+
  ggplot2::facet_wrap(~siteID,ncol = 1,scales="free_y")+
  ggplot2::theme(axis.text.x = element_text(size = 10, angle = 30, 
                                            hjust = 1, vjust = 1))+
  ggplot2::labs(title = "Mean macroinvertebrates per square meter",
                y = "mean abundance per square meter",
                x = "year - bout")
inv_abundance



```

### AIS Timeseries

Using the `tidyverse` collection, we can create a single, tidy dataframe that 
contains continuous discharge, temperature of surface water, and water quality 
data. This will make it easier to plot a faceted plot that will show stacked 
timeseries for each site.

```{r ais-plot, fig.height=12, fig.width=12}
# first, subset to columns of interest in the temperature of surface water data
TSW_30min_subset <- TSW_30min[
  ,c("siteID","endDateTime","surfWaterTempMean","finalQF")
]
# rename columns for joining
names(TSW_30min_subset) <- c("siteID",
                             "roundDate",
                             "surfWaterTempMean",
                             "surfWaterTempFinalQF")

# subset out all flags
TSW_30min_subset_clean <- TSW_30min_subset[
  (!is.na(TSW_30min_subset$surfWaterTempFinalQF)
   &TSW_30min_subset$surfWaterTempFinalQF==0)
  |is.na(TSW_30min_subset$surfWaterTempFinalQF),
]
CSD_30min_clean <- CSD_30min[
  CSD_30min$dischargeCountQF==0,
]
WAQ_30min_clean <- WAQ_30min[
  WAQ_30min$turbidityCountQF==0
  &WAQ_30min$turbidityMean<700,
]

# merge all three AIS dataframes, convert to tidy format, and produce plot
AIS_all <- dplyr::full_join(TSW_30min_subset_clean,CSD_30min_clean,
                            by=c("siteID","roundDate"))%>%
  dplyr::full_join(WAQ_30min_clean,by=c("siteID","roundDate"))%>%
  tidyr::pivot_longer(cols = c(surfWaterTempMean,dischargeMean,turbidityMean),
                      values_to = "meanValues",names_to = "timeseriesName")%>%
  ggplot2::ggplot(aes(x=roundDate,y=meanValues))+
  ggplot2::geom_line()+
  ggplot2::facet_grid(timeseriesName~siteID,scales = "free_y")

AIS_all
  
```


Now that you have the basic tools and knowledge on how to read and wrangle NEON
AIS data, go have fun working on your scientific questions!

